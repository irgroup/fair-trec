@inproceedings{ekstrand_fairness_2019,
	address = {New York, NY, USA},
	series = {{SIGIR}'19},
	title = {Fairness and {Discrimination} in {Retrieval} and {Recommendation}},
	isbn = {978-1-4503-6172-9},
	url = {http://doi.acm.org/10.1145/3331184.3331380},
	doi = {10.1145/3331184.3331380},
	publisher = {ACM},
	author = {Ekstrand, Michael D. and Burke, Robin and Diaz, Fernando},
	year = {2019},
	pages = {1403--1404}
}

@article{castillo_fairness_2019,
	title = {Fairness and {Transparency} in {Ranking}},
	volume = {52},
	issn = {0163-5840},
	url = {http://dl.acm.org/citation.cfm?id=3308774.3308783},
	doi = {10.1145/3308774.3308783},
	number = {2},
	urldate = {2019-02-04},
	journal = {ACM SIGIR Forum},
	author = {Castillo, Carlos},
	month = jan,
	year = {2019},
	pages = {64--71}
}

@misc{asia_biega_trec_2019,
	title = {{TREC} 2019 {Fair} {Ranking} {Track}},
	url = {https://fair-trec.github.io/},
	urldate = {2019-10-14},
	author = {{Asia Biega} and {Fernando Diaz} and {Michael Ekstrand} and {Sebastian Kohlmeier}},
	year = {2019}
}



@article{zehlike_reducing_2018,
	title = {Reducing {Disparate} {Exposure} in {Ranking}: {A} {Learning} {To} {Rank} {Approach}},
	shorttitle = {Reducing {Disparate} {Exposure} in {Ranking}},
	url = {http://arxiv.org/abs/1805.08716},
	language = {en},
	urldate = {2019-06-26},
	journal = {arXiv:1805.08716 [cs]},
	author = {Zehlike, Meike and Diehn, Gina-Theresa and Castillo, Carlos},
	month = may,
	year = {2018}
}


@techreport{burges_ranknet_2010,
	title = {From {RankNet} to {LambdaRank} to {LambdaMART}: {An} {Overview}},
	url = {https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/},
	number = {MSR-TR-2010-82},
	author = {Burges, Chris J.C.},
	month = jun,
	year = {2010}
}


@misc{ma_jma127/pyltr_2019,
	title = {jma127/pyltr},
	copyright = {BSD-3-Clause},
	url = {https://github.com/jma127/pyltr},
	urldate = {2019-10-14},
	author = {Ma, Jerry},
	month = oct,
	year = {2019},
	note = {original-date: 2015-08-17T05:42:11Z}
}


@misc{ivan_kitanovski_fair-search/fairsearch-deltr-python_2019,
	title = {fair-search/fairsearch-deltr-python},
	copyright = {Apache-2.0},
	url = {https://github.com/fair-search/fairsearch-deltr-python},
	abstract = {Disparate Exposure in Learning To Rank for Python. Contribute to fair-search/fairsearch-deltr-python development by creating an account on GitHub.},
	urldate = {2019-10-14},
	publisher = {Fair Search},
	author = {{Ivan Kitanovski}},
	month = oct,
	year = {2019},
	note = {original-date: 2019-03-08T18:47:49Z}
}

@article{zehlike_fairsearch:_2019,
	title = {{FairSearch}: {A} {Tool} {For} {Fairness} in {Ranked} {Search} {Results}},
	shorttitle = {{FairSearch}},
	url = {http://arxiv.org/abs/1905.13134},
	language = {en},
	urldate = {2019-06-11},
	journal = {arXiv:1905.13134 [cs]},
	author = {Zehlike, Meike and Sühr, Tom and Castillo, Carlos and Kitanovski, Ivan},
	month = may,
	year = {2019},
	note = {arXiv: 1905.13134}
}


@inproceedings{ammar_18,
    title={Construction of the Literature Graph in Semantic Scholar},
    author={Waleed Ammar and Dirk Groeneveld and Chandra Bhagavatula and Iz Beltagy and Miles Crawford and Doug Downey and Jason Dunkelberger and Ahmed Elgohary and Sergey Feldman and Vu Ha and Rodney Kinney and Sebastian Kohlmeier and Kyle Lo and Tyler Murray and Hsu-Han Ooi and Matthew Peters and Joanna Power and Sam Skjonsberg and Lucy Lu Wang and Chris Wilhelm and Zheng Yuan and Madeleine van Zuylen and Oren Etzioni},
    booktitle={NAACL},
    year={2018},
    url={https://www.semanticscholar.org/paper/09e3cf5704bcb16e6657f6ceed70e93373a54618}
}

@software{malte_bonart_2019_3514668,
  author       = {Malte Bonart},
  title        = {irgroup/fair-trec: trec 2019 conference release},
  month        = oct,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {v1.0.0-alpha},
  doi          = {10.5281/zenodo.3514668},
  url          = {https://doi.org/10.5281/zenodo.3514668}
}


@inproceedings{chapelle_expected_2009,
	address = {Hong Kong, China},
	title = {Expected reciprocal rank for graded relevance},
	isbn = {978-1-60558-512-3},
	url = {http://portal.acm.org/citation.cfm?doid=1645953.1646033},
	doi = {10.1145/1645953.1646033},
	abstract = {While numerous metrics for information retrieval are available in the case of binary relevance, there is only one commonly used metric for graded relevance, namely the Discounted Cumulative Gain (DCG). A drawback of DCG is its additive nature and the underlying independence assumption: a document in a given position has always the same gain and discount independently of the documents shown above it. Inspired by the “cascade” user model, we present a new editorial metric for graded relevance which overcomes this diﬃculty and implicitly discounts documents which are shown below very relevant documents. More precisely, this new metric is deﬁned as the expected reciprocal length of time that the user will take to ﬁnd a relevant document. This can be seen as an extension of the classical reciprocal rank to the graded relevance case and we call this metric Expected Reciprocal Rank (ERR). We conduct an extensive evaluation on the query logs of a commercial search engine and show that ERR correlates better with clicks metrics than other editorial metrics.},
	language = {en},
	urldate = {2019-06-26},
	booktitle = {Proceeding of the 18th {ACM} conference on {Information} and knowledge management - {CIKM} '09},
	publisher = {ACM Press},
	author = {Chapelle, Olivier and Metlzer, Donald and Zhang, Ya and Grinspan, Pierre},
	year = {2009},
	pages = {621},
	file = {Chapelle et al. - 2009 - Expected reciprocal rank for graded relevance.pdf:/home/mbonart/Zotero/storage/CQ5CFKY3/Chapelle et al. - 2009 - Expected reciprocal rank for graded relevance.pdf:application/pdf}
}


@inproceedings{biega_equity_2018,
	address = {New York, NY, USA},
	series = {{SIGIR} '18},
	title = {Equity of {Attention}: {Amortizing} {Individual} {Fairness} in {Rankings}},
	isbn = {978-1-4503-5657-2},
	shorttitle = {Equity of {Attention}},
	url = {http://doi.acm.org/10.1145/3209978.3210063},
	doi = {10.1145/3209978.3210063},
	abstract = {Rankings of people and items are at the heart of selection-making, match-making, and recommender systems, ranging from employment sites to sharing economy platforms. As ranking positions influence the amount of attention the ranked subjects receive, biases in rankings can lead to unfair distribution of opportunities and resources such as jobs or income. This paper proposes new measures and mechanisms to quantify and mitigate unfairness from a bias inherent to all rankings, namely, the position bias which leads to disproportionately less attention being paid to low-ranked subjects. Our approach differs from recent fair ranking approaches in two important ways. First, existing works measure unfairness at the level of subject groups while our measures capture unfairness at the level of individual subjects, and as such subsume group unfairness. Second, as no single ranking can achieve individual attention fairness, we propose a novel mechanism that achieves amortized fairness, where attention accumulated across a series of rankings is proportional to accumulated relevance. We formulate the challenge of achieving amortized individual fairness subject to constraints on ranking quality as an online optimization problem and show that it can be solved as an integer linear program. Our experimental evaluation reveals that unfair attention distribution in rankings can be substantial, and demonstrates that our method can improve individual fairness while retaining high ranking quality.},
	urldate = {2019-07-02},
	booktitle = {The 41st {International} {ACM} {SIGIR} {Conference} on {Research} \& {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Biega, Asia J. and Gummadi, Krishna P. and Weikum, Gerhard},
	year = {2018},
	note = {event-place: Ann Arbor, MI, USA},
	keywords = {article, theoretical, fairness},
	pages = {405--414},
	file = {ACM Full Text PDF:/home/mbonart/Zotero/storage/IBX6S6K7/Biega et al. - 2018 - Equity of Attention Amortizing Individual Fairnes.pdf:application/pdf}
}


@article{singh_fairness_2018,
	title = {Fairness of {Exposure} in {Rankings}},
	url = {http://arxiv.org/abs/1802.07281},
	doi = {10.1145/3219819.3220088},
	abstract = {Rankings are ubiquitous in the online world today. As we have transitioned from finding books in libraries to ranking products, jobs, job applicants, opinions and potential romantic partners, there is a substantial precedent that ranking systems have a responsibility not only to their users but also to the items being ranked. To address these often conflicting responsibilities, we propose a conceptual and computational framework that allows the formulation of fairness constraints on rankings in terms of exposure allocation. As part of this framework, we develop efficient algorithms for finding rankings that maximize the utility for the user while provably satisfying a specifiable notion of fairness. Since fairness goals can be application specific, we show how a broad range of fairness constraints can be implemented using our framework, including forms of demographic parity, disparate treatment, and disparate impact constraints. We illustrate the effect of these constraints by providing empirical results on two ranking problems.},
	urldate = {2019-07-05},
	journal = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining  - KDD '18},
	author = {Singh, Ashudeep and Joachims, Thorsten},
	year = {2018},
	note = {arXiv: 1802.07281},
	pages = {2219--2228},
	annote = {Comment: In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, London, UK, 2018},
	file = {arXiv\:1802.07281 PDF:/home/mbonart/Zotero/storage/IKU4I5W9/Singh and Joachims - 2018 - Fairness of Exposure in Rankings.pdf:application/pdf;arXiv.org Snapshot:/home/mbonart/Zotero/storage/NA5SGGR8/1802.html:text/html}
}



@misc{noauthor_o19s/elasticsearch-learning--rank_2019,
	title = {o19s/elasticsearch-learning-to-rank},
	copyright = {Apache-2.0},
	url = {https://github.com/o19s/elasticsearch-learning-to-rank},
	abstract = {Plugin to integrate Learning to Rank (aka machine learning for better relevance) with Elasticsearch},
	urldate = {2019-10-22},
	author = {OpenSource Connections},
	month = oct,
	year = {2019},
	note = {original-date: 2016-12-25T03:19:01Z}
}